"""
Core constraint consistency checking logic.
Implements constraint extraction, establishment checking, and violation detection.

ARCHITECTURAL RULE: Treat as CONSTRAINT PERSISTENCE, not QA.
A single violated constraint â†’ label = 0 (inconsistent).

STRICT REQUIREMENTS:
1. Extract constraints from backstory using Qwen (JSON output)
2. For each constraint:
   a. Retrieve candidate chunks via Pathway
   b. Find earliest chunk that ESTABLISHES constraint
   c. Record established_at (narrative_position)
3. Retrieve only chunks with position > established_at
4. Search for violations using targeted retrieval queries
5. Run binary LLM checks
6. If any constraint is violated â†’ output 0, else 1

RETRIEVAL RULES:
- NEVER scan all chunks
- ALWAYS retrieve first, then verify with LLM
- Use reranker before LLM calls

DECISION RULE:
- One violation = contradiction
- No voting, no weighting, no averaging
"""

import json
import config
import prompts
from models import generate_with_qwen
from evaluation_utils import (
    parse_llm_output,
    log_step,
    sanity_check,
    validate_retrieval_quality
)


def extract_constraints(model, tokenizer, statement):
    """
    Extract logical constraints from backstory statement using Qwen.
    Uses structured JSON output for deterministic extraction.
    
    STRICT: Temperature = 0.0 for reproducibility.
    
    Args:
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        statement: Backstory statement text to analyze
        
    Returns:
        List[str]: Extracted constraint strings
    """
    print("\n" + "="*60)
    print("[STEP 1] CONSTRAINT EXTRACTION")
    print("="*60)
    print(f"Statement: {statement[:150]}..." if len(statement) > 150 else f"Statement: {statement}")
    
    prompt = prompts.CONSTRAINT_EXTRACTION_PROMPT.format(statement=statement)
    
    # Generate with Qwen (temperature=0.01, near-deterministic)
    # Enable debug for first call to see what's happening
    # Increased tokens for DeepSeek-R1's reasoning chains
    debug_enabled = not hasattr(extract_constraints, '_first_call_done')
    output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=1024, debug=debug_enabled)
    extract_constraints._first_call_done = True
    
    # Parse JSON output - use json_array format
    constraints = parse_llm_output(output, expected_format="json_array")
    
    if not constraints:
        print("âš ï¸  WARNING: No constraints extracted from LLM output")
        print(f"Raw output (first 300 chars): {output[:300]}")
    else:
        print(f"âœ“ Extracted {len(constraints)} constraints")
    
    # Limit to max constraints
    constraints = constraints[:config.MAX_CONSTRAINTS_PER_STATEMENT]
    
    log_step(
        "extract_constraints",
        {"statement": statement},
        {"constraints": constraints},
        {"raw_output": output}
    )
    
    print(f"\nâœ“ Extracted {len(constraints)} constraints:")
    for i, c in enumerate(constraints, 1):
        preview = c[:80] + "..." if len(c) > 80 else c
        print(f"  {i}. {preview}")
    
    return constraints


def find_constraint_establishment(vector_store, model, tokenizer, constraint, reranker):
    """
    Find where a constraint is FIRST ESTABLISHED in the novel.
    Uses retrieval-first approach: Pathway retrieve â†’ rerank â†’ binary LLM verify.
    
    CRITICAL: Returns the EARLIEST position where constraint is established.
    This becomes the filter threshold for violation search.
    
    Args:
        vector_store: PathwayVectorStore instance
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        constraint: Constraint string to locate
        reranker: bge-reranker-large CrossEncoder
        
    Returns:
        Dict with {
            'found': bool,
            'position': int or None (narrative_position),
            'text': str or None,
            'confidence': float
        }
    """
    print("\n" + "="*60)
    print("[STEP 2] CONSTRAINT ESTABLISHMENT")
    print("="*60)
    print(f"Constraint: {constraint[:80]}...")
    
    # Step 1: Retrieve candidate chunks (NO position filter - search entire document)
    print("\nRetrieving candidates from Pathway store...")
    retrieved_chunks = vector_store.retrieve(
        query=constraint,
        position_filter=None,  # Search entire document
        top_k=config.RETRIEVAL_TOP_K
    )
    
    if not retrieved_chunks:
        print("âš  No chunks retrieved")
        return {
            'found': False,
            'position': None,
            'text': None,
            'confidence': 0.0
        }
    
    print(f"Retrieved {len(retrieved_chunks)} chunks")
    
    # EARLY SKIP: If top retrieval score is very low, constraint likely not in novel
    top_retrieval_score = max([c.get('score', 0) for c in retrieved_chunks]) if retrieved_chunks else 0
    if top_retrieval_score < 0.45:
        print(f"âš  Top retrieval score too low ({top_retrieval_score:.3f}) - constraint likely absent")
        return {
            'found': False,
            'position': None,
            'text': None,
            'confidence': 0.0
        }
    
    # Step 2: Rerank chunks (MUST happen before LLM verification)
    print(f"\nReranking with bge-reranker-large...")
    pairs = [[constraint, chunk['text']] for chunk in retrieved_chunks]
    rerank_scores = reranker.predict(pairs)
    
    # Attach rerank scores
    for i, chunk in enumerate(retrieved_chunks):
        chunk['rerank_score'] = float(rerank_scores[i])
    
    # Sort by rerank score descending
    retrieved_chunks.sort(key=lambda x: x['rerank_score'], reverse=True)
    
    # Take top-k after reranking
    top_chunks = retrieved_chunks[:config.RERANK_TOP_K]
    
    # Reranking completed - checking chunks
    
    # Step 3: Binary LLM verification - find EARLIEST establishment
    # Sort by narrative_position ascending to check earliest first
    top_chunks_by_position = sorted(top_chunks, key=lambda x: x['narrative_position'])
    
    # OPTIMIZATION: If top rerank score is very high, auto-accept (skip LLM)
    top_score = top_chunks_by_position[0]['rerank_score'] if top_chunks_by_position else 0
    if top_score >= config.ESTABLISHMENT_AUTO_ACCEPT_SCORE:
        chunk = top_chunks_by_position[0]
        position = chunk['narrative_position']
        print(f"\nâœ“ Constraint ESTABLISHED at position {position} (high score: {top_score:.3f}, skipped LLM)")
        return {
            'found': True,
            'position': position,
            'text': chunk['text'],
            'confidence': chunk['rerank_score']
        }
    
    # Otherwise check with LLM (check top 3 instead of all 5 for speed)
    for chunk in top_chunks_by_position[:3]:
        prompt = prompts.ESTABLISHMENT_CHECK_PROMPT.format(
            constraint=constraint,
            passage=chunk['text']
        )
        
        output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=50)
        result = parse_llm_output(output, expected_format="binary")
        
        # RELAXED: Accept ESTABLISHES or strong mentions
        if result == "ESTABLISHES" or "ESTABLISH" in output.upper():
            position = chunk['narrative_position']
            print(f"\nâœ“ Constraint ESTABLISHED at position {position}")
            
            birth_info = {
                'found': True,
                'position': position,
                'text': chunk['text'],
                'confidence': chunk['rerank_score']
            }
            
            log_step(
                "find_constraint_establishment",
                {"constraint": constraint},
                birth_info,
                {"chunks_checked": len(top_chunks_by_position)}
            )
            
            return birth_info
    
    # Not found in top chunks
    print("\nâš  Constraint establishment NOT FOUND in top chunks")
    return {
        'found': False,
        'position': None,
        'text': None,
        'confidence': 0.0
    }


def generate_violation_query(model, tokenizer, constraint):
    """
    Generate a targeted search query to find potential violations.
    
    Purpose: Create semantically relevant query for dense retrieval.
    Example: "John is a doctor" â†’ "John lawyer attorney legal profession"
    
    Args:
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        constraint: Constraint to check for violations
        
    Returns:
        str: Generated violation search query
    """
    print("\n" + "="*60)
    print("[STEP 3] VIOLATION QUERY GENERATION")
    print("="*60)
    print(f"Constraint: {constraint[:80]}...")
    
    prompt = prompts.VIOLATION_QUERY_PROMPT.format(constraint=constraint)
    
    output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=100)
    query = parse_llm_output(output, expected_format="text")
    
    print(f"\nâœ“ Generated query: {query}")
    
    log_step(
        "generate_violation_query",
        {"constraint": constraint},
        {"query": query}
    )
    
    return query


def assess_retrieval_quality(
    model,
    tokenizer,
    constraint,
    query,
    retrieved_chunks,
    logger=None
):
    """
    Assess whether retrieved chunks are useful for finding violations.
    
    Part of self-refinement loop (Section 3.7 of paper).
    
    Args:
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        constraint: Constraint being checked
        query: Search query used
        retrieved_chunks: List of retrieved chunk dicts
        logger: Optional logger for evaluation.py integration
        
    Returns:
        str: "GOOD" if quality is acceptable, "POOR" if refinement needed
    """
    if not retrieved_chunks:
        return "POOR"  # No results = poor quality
    
    # Take top 3 chunks for quality assessment
    top_chunks = retrieved_chunks[:3]
    passages_text = "\n\n---\n\n".join([
        f"Passage {i+1}: {chunk['text'][:200]}..."
        for i, chunk in enumerate(top_chunks)
    ])
    
    prompt = prompts.RETRIEVAL_QUALITY_PROMPT.format(
        constraint=constraint,
        query=query,
        passages=passages_text
    )
    
    output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=10)
    
    # Parse binary output: GOOD or POOR
    from evaluation import parse_binary_keyword_safe
    quality = parse_binary_keyword_safe(output, "GOOD", "POOR", logger)
    
    if quality is True:
        return "GOOD"
    elif quality is False:
        return "POOR"
    else:
        # Ambiguous or not found - default to accepting results
        return "GOOD"


def refine_violation_query(
    model,
    tokenizer,
    constraint,
    original_query,
    poor_chunks,
    logger=None
):
    """
    Refine search query when initial retrieval was poor.
    
    Part of self-refinement loop (Section 3.7 of paper).
    
    Args:
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        constraint: Constraint being checked
        original_query: Original search query that didn't work well
        poor_chunks: Retrieved chunks that were not useful
        logger: Optional logger for evaluation.py integration
        
    Returns:
        str: Refined search query
    """
    # Show model why previous query failed
    passages_text = "\n\n---\n\n".join([
        f"Passage {i+1}: {chunk['text'][:150]}..."
        for i, chunk in enumerate(poor_chunks[:3])
    ])
    
    prompt = prompts.QUERY_REFINEMENT_PROMPT.format(
        constraint=constraint,
        original_query=original_query,
        passages=passages_text
    )
    
    output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=50)
    
    # Parse plain text output
    from evaluation import parse_plain_text_safe
    refined_query = parse_plain_text_safe(output, logger)
    
    return refined_query if refined_query else original_query  # Fallback to original


def search_for_violations_with_refinement(
    vector_store,
    model,
    tokenizer,
    constraint,
    violation_query,
    established_at,
    reranker,
    max_refinement_attempts=2,
    logger=None
):
    """
    Search for violations with self-refinement loop (Section 3.7 of paper).
    
    SELF-REFINEMENT PROCESS:
    1. Retrieve chunks with initial query
    2. Assess retrieval quality (GOOD/POOR)
    3. If POOR and attempts < max:
       a. Refine query
       b. Re-retrieve with refined query
       c. Repeat assessment
    4. Use best retrieval result for violation checking
    
    BOUNDED REFINEMENT:
    - Max refinement attempts prevents instability
    - Always returns result (even if quality remains poor)
    
    Args:
        vector_store: PathwayVectorStore instance
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        constraint: Constraint being checked
        violation_query: Initial search query
        established_at: Position where constraint was established
        reranker: bge-reranker-large CrossEncoder
        max_refinement_attempts: Max number of query refinement iterations (default: 2)
        logger: Optional logger from evaluation.py
        
    Returns:
        Tuple[bool, Optional[Dict]]:
            - violation_found: True if violation detected
            - evidence: Dict with violation details or None
    """
    print("\n" + "="*60)
    print("[STEP 4] VIOLATION SEARCH (with self-refinement)")
    print("="*60)
    print(f"Constraint: {constraint[:80]}...")
    print(f"Established at: position {established_at}")
    print(f"Max refinement attempts: {max_refinement_attempts}")
    
    current_query = violation_query
    best_chunks = None
    
    for attempt in range(max_refinement_attempts + 1):  # +1 for initial attempt
        print(f"\n--- Attempt {attempt + 1}/{max_refinement_attempts + 1} ---")
        print(f"Query: {current_query}")
        
        # Retrieve chunks
        print(f"\nRetrieving from Pathway (position_filter={established_at + 1})...")
        retrieved_chunks = vector_store.retrieve(
            query=current_query,
            position_filter=established_at + 1,  # ONLY chunks AFTER establishment
            top_k=config.RETRIEVAL_TOP_K
        )
        
        if not retrieved_chunks:
            print("âš  No chunks retrieved")
            if attempt < max_refinement_attempts:
                print("Refining query and retrying...")
                current_query = refine_violation_query(
                    model, tokenizer, constraint, current_query, [], logger
                )
                continue
            else:
                print("âœ“ No chunks found after all attempts (no violation)")
                return False, None
        
        print(f"Retrieved {len(retrieved_chunks)} chunks")
        
        # FIXED: Assess quality using retrieval scores (not broken LLM assessment)
        print("\nAssessing retrieval quality...")
        retrieval_scores = [c.get('score', 0) for c in retrieved_chunks]
        max_score = max(retrieval_scores) if retrieval_scores else 0
        
        # Score-based quality assessment (MUCH faster and more reliable)
        if max_score >= 0.60:
            quality = "GOOD"
        elif max_score >= 0.50:
            quality = "ACCEPTABLE"
        else:
            quality = "POOR"
        
        print(f"Quality: {quality} (max_score: {max_score:.3f})")
        
        if quality in ["GOOD", "ACCEPTABLE"] or attempt == max_refinement_attempts:
            # Use these chunks (good/acceptable quality or last attempt)
            best_chunks = retrieved_chunks
            break
        else:
            # Quality is POOR and we have more attempts - refine query
            print("Quality is POOR, refining query...")
            current_query = refine_violation_query(
                model, tokenizer, constraint, current_query, retrieved_chunks, logger
            )
    
    # Now proceed with violation checking using best_chunks
    print(f"\nProceeding with violation checks (using {len(best_chunks)} chunks)")
    
    # Rerank chunks
    print(f"\nReranking with bge-reranker-large...")
    pairs = [[current_query, chunk['text']] for chunk in best_chunks]
    rerank_scores = reranker.predict(pairs)
    
    # Attach rerank scores
    for i, chunk in enumerate(best_chunks):
        chunk['rerank_score'] = float(rerank_scores[i])
    
    # Sort by rerank score descending
    best_chunks.sort(key=lambda x: x['rerank_score'], reverse=True)
    top_chunks = best_chunks[:config.RERANK_TOP_K]
    
    print(f"Top {len(top_chunks)} chunks after reranking:")
    for i, chunk in enumerate(top_chunks[:3], 1):
        print(f"  {i}. pos={chunk['narrative_position']}, rerank_score={chunk['rerank_score']:.3f}")
    
    # Get establishment context
    establishment_chunk = vector_store.get_chunk_by_position(established_at)
    establishment_text = establishment_chunk['text'] if establishment_chunk else "N/A"
    
    # Binary LLM verification (check top 3 only for 40% speedup)
    check_limit = min(3, len(top_chunks))
    print(f"\\nLLM verification on top {check_limit} chunks...")
    for i, chunk in enumerate(top_chunks[:check_limit], 1):
        print(f"\n[DEBUG] Checking chunk {i}/{check_limit}:")
        print(f"  Position: {chunk['narrative_position']}")
        print(f"  Rerank score: {chunk['rerank_score']:.3f}")
        print(f"  Chunk preview: {chunk['text'][:120]}...")
        
        prompt = prompts.VIOLATION_CHECK_PROMPT.format(
            constraint=constraint,
            establishment_context=establishment_text[:300],
            passage=chunk['text']
        )
        
        output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=50)
        result = parse_llm_output(output, expected_format="binary")
        
        print(f"  LLM output: {output[:100]}...")
        print(f"  Parsed as: {result}")
        
        print(f"  Chunk {i} (pos={chunk['narrative_position']}): {result}")
        
        if result == "VIOLATES":
            # Check if it's a revision
            
            is_revision = check_if_revision(
                model,
                tokenizer,
                constraint,
                establishment_text,
                chunk['text']
            )
            
            if is_revision:
                print(f"  â†’ Classified as REVISION (intentional change, not error)")
                continue
            
            # TRUE VIOLATION DETECTED
            position = chunk['narrative_position']
            print(f"\nâœ— VIOLATION CONFIRMED at position {position}")
            
            evidence = {
                'constraint': constraint,
                'established_at': established_at,
                'establishment_text': establishment_text[:500],
                'violation_position': position,
                'violation_text': chunk['text'][:500],
                'rerank_score': chunk['rerank_score'],
                'refined_query': current_query if current_query != violation_query else None
            }
            
            # Log violation with evaluation.py if logger provided
            if logger:
                from evaluation import log_violation
                log_violation(logger, constraint, position, chunk['text'], is_revision=False)
            
            return True, evidence
    
    # No violation found
    print("\nâœ“ No violations detected")
    return False, None


def search_for_violations_with_nli(
    vector_store,
    model,
    tokenizer,
    nli_model,
    nli_tokenizer,
    constraint,
    violation_query,
    established_at,
    reranker
):
    """
    Search for constraint violations using NLI filter + two-pass Qwen verification.
    
    CRITICAL IMPROVEMENTS (from 57% â†’ 85-95%):
    1. NLI contradiction filter (high-recall, catches most violations)
    2. Two-pass Qwen verification (removes false positives)
    3. Strict parsing logic (VIOLATES only)
    4. Always returns tuple (never None)
    
    Args:
        vector_store: PathwayVectorStore instance
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        nli_model: RoBERTa-large-MNLI model
        nli_tokenizer: NLI tokenizer
        constraint: Constraint text being checked
        violation_query: Search query for violations
        established_at: Position where constraint was established
        reranker: bge-reranker-large CrossEncoder
        
    Returns:
        Tuple[bool, Optional[Dict]]: Always returns (violation_found, evidence or None)
    """
    print("\n" + "="*60)
    print("[STEP 4] VIOLATION SEARCH (NLI + Two-Pass)")
    print("="*60)
    print(f"Constraint: {constraint[:80]}...")
    print(f"Established at: position {established_at}")
    
    # Step 1: Retrieve chunks AFTER constraint establishment
    print(f"\nRetrieving from Pathway (position_filter={established_at + 1})...")
    retrieved_chunks = vector_store.retrieve(
        query=violation_query,
        position_filter=established_at + 1,
        top_k=config.RETRIEVAL_TOP_K
    )
    
    if not retrieved_chunks:
        print("âœ“ No chunks retrieved after establishment (no text to check)")
        return False, None  # Always return tuple
    
    print(f"Retrieved {len(retrieved_chunks)} chunks")
    
    # Step 2: Rerank chunks
    print(f"\nReranking with bge-reranker-large...")
    pairs = [[violation_query, chunk['text']] for chunk in retrieved_chunks]
    rerank_scores = reranker.predict(pairs)
    
    for i, chunk in enumerate(retrieved_chunks):
        chunk['rerank_score'] = float(rerank_scores[i])
    
    retrieved_chunks.sort(key=lambda x: x['rerank_score'], reverse=True)
    top_chunks = retrieved_chunks[:config.RERANK_TOP_K]
    
    print(f"Top {len(top_chunks)} chunks after reranking")
    
    # Step 3: NLI FILTERING (HIGH-RECALL FILTER WITH SCORES)
    if nli_model is not None and nli_tokenizer is not None:
        print(f"\n[NLI FILTER] Checking for potential contradictions...")
        from models import check_contradiction_nli
        
        nli_filtered = []
        for chunk in top_chunks:
            is_contradiction, nli_score = check_contradiction_nli(
                nli_model,
                nli_tokenizer,
                premise=constraint,
                hypothesis=chunk['text'],
                return_score=True
            )
            if is_contradiction:
                chunk['nli_score'] = nli_score  # Store score for soft aggregation
                nli_filtered.append(chunk)
        
        print(f"NLI filter: {len(nli_filtered)}/{len(top_chunks)} chunks flagged as potential contradictions")
        
        if not nli_filtered:
            print("âœ“ NLI found no contradictions â†’ No violations")
            return False, None  # Always return tuple
        
        # Use NLI-filtered chunks for Qwen verification
        top_chunks = nli_filtered
    
    # Step 4: Get establishment context
    establishment_chunk = vector_store.get_chunk_by_position(established_at)
    establishment_text = establishment_chunk['text'] if establishment_chunk else "N/A"
    
    # Step 5: FIRST PASS - Qwen verification (WITH INSUFFICIENT HANDLING)
    print(f"\nâœ“ Qwen verification (Pass 1) on {len(top_chunks)} NLI-filtered chunks...")
    for i, chunk in enumerate(top_chunks, 1):
        prompt = prompts.VIOLATION_CHECK_PROMPT.format(
            constraint=constraint,
            establishment_context=establishment_text[:300],
            passage=chunk['text']
        )
        
        output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=50)
        result = parse_llm_output(output, expected_format="text").upper()
        
        print(f"  Chunk {i}: {result}")
        
        # Handle INSUFFICIENT evidence (soft output)
        if result == "INSUFFICIENT":
            print(f"  â†’ INSUFFICIENT evidence (skipping)")
            continue
        
        # Handle SUPPORTS (compatible with constraint)
        if result == "SUPPORTS":
            print(f"  â†’ SUPPORTS constraint (no violation)")
            continue
        
        # STRICT PARSING: Only "VIOLATES" proceeds to second pass
        if result == "VIOLATES":
            # Step 6: SECOND PASS - Verify it's a TRUE violation
            print(f"\n  [Pass 2] Verifying TRUE_VIOLATION...")
            
            verify_prompt = prompts.TRUE_VIOLATION_CHECK_PROMPT.format(
                constraint=constraint,
                evidence=chunk['text'][:400]
            )
            
            verify_output = generate_with_qwen(model, tokenizer, verify_prompt, max_new_tokens=50)
            verify_result = parse_llm_output(verify_output, expected_format="binary")
            
            print(f"  Second check: {verify_result}")
            
            # ONLY confirm if both passes agree it's a violation
            if verify_result == "TRUE_VIOLATION":
                # Step 7: Check for legitimate revision
                is_revision = check_if_revision(
                    model,
                    tokenizer,
                    constraint,
                    establishment_text,
                    chunk['text']
                )
                
                if is_revision:
                    print(f"  â†’ REVISION (intentional change)")
                    continue
                
                # CONFIRMED TRUE VIOLATION
                position = chunk['narrative_position']
                print(f"\nâœ— VIOLATION CONFIRMED at position {position}")
                
                evidence = {
                    'constraint': constraint,
                    'established_at': established_at,
                    'establishment_text': establishment_text[:500],
                    'violation_position': position,
                    'violation_text': chunk['text'][:500],
                    'rerank_score': chunk['rerank_score'],
                    'nli_score': chunk.get('nli_score', 0.8)  # Include NLI score for soft aggregation
                }
                
                return True, evidence  # Always return tuple
            else:
                print(f"  â†’ COMPATIBLE (false positive filtered)")
    
    # No violation found
    print("\nâœ“ No violations detected")
    return False, None  # Always return tuple


def search_for_violations(
    vector_store,
    model,
    tokenizer,
    constraint,
    violation_query,
    established_at,
    reranker
):
    """
    LEGACY: Search for constraint violations (WITHOUT NLI filter).
    
    Use search_for_violations_with_nli() instead for better accuracy.
    
    This function is kept for backwards compatibility.
    
    Args:
        vector_store: PathwayVectorStore instance
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        constraint: Constraint being checked
        violation_query: Search query for violations
        established_at: Position where constraint was established
        reranker: bge-reranker-large CrossEncoder
        
    Returns:
        Tuple[bool, Optional[Dict]]: Always returns (violation_found, evidence or None)
    """
    print("\n" + "="*60)
    print("[STEP 4] VIOLATION SEARCH")
    print("="*60)
    print(f"Constraint: {constraint[:80]}...")
    print(f"Established at: position {established_at}")
    print(f"Searching after: position {established_at + 1}")
    
    # Step 1: Retrieve chunks AFTER constraint establishment (position filtering)
    print(f"\nRetrieving from Pathway (position_filter={established_at + 1})...")
    retrieved_chunks = vector_store.retrieve(
        query=violation_query,
        position_filter=established_at + 1,  # ONLY chunks AFTER establishment
        top_k=config.RETRIEVAL_TOP_K
    )
    
    if not retrieved_chunks:
        print("âœ“ No chunks retrieved after establishment (no text to check)")
        return False, None  # ALWAYS return tuple, never None
    
    print(f"Retrieved {len(retrieved_chunks)} chunks")
    
    # Step 2: Rerank chunks (before LLM verification)
    print(f"\nReranking with bge-reranker-large...")
    pairs = [[violation_query, chunk['text']] for chunk in retrieved_chunks]
    rerank_scores = reranker.predict(pairs)
    
    # Attach rerank scores
    for i, chunk in enumerate(retrieved_chunks):
        chunk['rerank_score'] = float(rerank_scores[i])
    
    # Sort by rerank score descending
    retrieved_chunks.sort(key=lambda x: x['rerank_score'], reverse=True)
    top_chunks = retrieved_chunks[:config.RERANK_TOP_K]
    
    print(f"Top {len(top_chunks)} chunks after reranking:")
    for i, chunk in enumerate(top_chunks[:3], 1):
        print(f"  {i}. pos={chunk['narrative_position']}, rerank_score={chunk['rerank_score']:.3f}")
    
    # Get establishment context for LLM prompt
    establishment_chunk = vector_store.get_chunk_by_position(established_at)
    establishment_text = establishment_chunk['text'] if establishment_chunk else "N/A"
    
    # Step 3: Binary LLM verification - check top 3 chunks only
    check_limit = min(3, len(top_chunks))
    print(f"\\nLLM verification on top {check_limit} chunks...")
    for i, chunk in enumerate(top_chunks[:check_limit], 1):
        print(f"\n[DEBUG] Direct check {i}/{check_limit}:")
        print(f"  Constraint: {constraint[:60]}...")
        print(f"  Position: {chunk['narrative_position']}")
        print(f"  Chunk preview: {chunk['text'][:120]}...")
        
        prompt = prompts.VIOLATION_CHECK_PROMPT.format(
            constraint=constraint,
            establishment_context=establishment_text[:300],
            passage=chunk['text']
        )
        
        output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=50)
        result = parse_llm_output(output, expected_format="binary")
        
        print(f"  LLM output: {output[:100]}...")
        print(f"  Parsed as: {result}")
        
        if result == "VIOLATES":
            # Step 4: Check if it's a valid revision (intentional change)
            
            is_revision = check_if_revision(
                model,
                tokenizer,
                constraint,
                establishment_text,
                chunk['text']
            )
            
            if is_revision:
                print(f"  â†’ Classified as REVISION (intentional change, not error)")
                continue  # Not a true violation, keep searching
            
            # TRUE VIOLATION DETECTED
            position = chunk['narrative_position']
            print(f"\nâœ— VIOLATION CONFIRMED at position {position}")
            
            evidence = {
                'constraint': constraint,
                'established_at': established_at,
                'establishment_text': establishment_text[:500],
                'violation_position': position,
                'violation_text': chunk['text'][:500],
                'rerank_score': chunk['rerank_score']
            }
            
            # Sanity check
            is_valid, issues = sanity_check(constraint, chunk['text'], result)
            if not is_valid:
                print(f"  Warning: Sanity check failed: {issues}")
            
            log_step(
                "search_for_violations",
                {
                    "constraint": constraint,
                    "query": violation_query,
                    "established_at": established_at
                },
                {"violation_found": True, "evidence": evidence}
            )
            
            return True, evidence
    
    # No violation found in any chunk
    print("\nâœ“ No violations detected")
    
    log_step(
        "search_for_violations",
        {
            "constraint": constraint,
            "query": violation_query,
            "established_at": established_at
        },
        {"violation_found": False}
    )
    
    return False, None


def check_if_revision(model, tokenizer, constraint, establishment_text, potential_violation_text):
    """
    Check if an apparent violation is actually a legitimate revision.
    Handles intentional character development, plot twists, retcons.
    
    Examples of revisions (NOT violations):
    - "John was a doctor" â†’ "John quit medicine and became a lawyer" (explicit change)
    - "Sarah hated dogs" â†’ "After therapy, Sarah adopted a dog" (character growth)
    
    Examples of violations (inconsistencies):
    - "John is a doctor" â†’ "John the lawyer walked into court" (no transition)
    - "Sarah lives in NYC" â†’ "Sarah returned to her LA apartment" (no explanation)
    
    Args:
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        constraint: Original constraint
        establishment_text: Where constraint was established
        potential_violation_text: Text that may contain violation
        
    Returns:
        bool: True if this is a valid revision, False if true violation
    """
    prompt = prompts.REVISION_CHECK_PROMPT.format(
        constraint=constraint,
        establishment_context=establishment_text[:300],
        violation_passage=potential_violation_text[:300]
    )
    
    output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=50)
    result = parse_llm_output(output, expected_format="binary")
    
    is_revision = (result == "REVISION")
    
    log_step(
        "check_if_revision",
        {
            "constraint": constraint,
            "establishment": establishment_text[:100],
            "potential_violation": potential_violation_text[:100]
        },
        {"is_revision": is_revision}
    )
    
    return is_revision


def prioritize_constraints(constraints):
    """
    Prioritize constraints by type for maximum accuracy.
    
    Priority order:
    1. PROHIBITION (most violatable)
    2. BELIEF (sometimes violatable)
    3. MOTIVATION (rarely violatable)
    4. BACKGROUND_FACT (not violatable)
    5. FEAR (rarely violatable)
    
    Args:
        constraints: List of constraint dicts with 'type' and 'constraint' keys
        
    Returns:
        List of constraints sorted by priority
    """
    priority_map = {
        'PROHIBITION': 1,
        'BELIEF': 2,
        'MOTIVATION': 3,
        'FEAR': 4,
        'BACKGROUND_FACT': 5
    }
    
    def get_priority(constraint_obj):
        constraint_type = constraint_obj.get('type', 'UNKNOWN').upper()
        return priority_map.get(constraint_type, 99)
    
    sorted_constraints = sorted(constraints, key=get_priority)
    
    print(f"\n[CONSTRAINT PRIORITIZATION]")
    print(f"Original order: {[c.get('type', 'UNKNOWN').upper() for c in constraints]}")
    print(f"Prioritized order: {[c.get('type', 'UNKNOWN').upper() for c in sorted_constraints]}")
    
    return sorted_constraints


def check_constraint_consistency(
    vector_store,
    model,
    tokenizer,
    reranker,
    statement,
    novel_id,
    nli_model=None,
    nli_tokenizer=None,
    enable_refinement=True,
    max_refinement_attempts=2,
    logger=None
):
    """
    Main pipeline for checking constraint consistency.
    
    ARCHITECTURE (100% PAPER COMPLIANT + NLI IMPROVEMENTS):
    1. Extract constraints from statement (WITH TYPES - Section 3.3)
    2. For each constraint:
       a. Skip BACKGROUND_FACT (time-bound descriptive facts don't need violation search)
       b. Find establishment position (earliest occurrence)
       c. Generate violation query
       d. Search for violations WITH NLI FILTER + TWO-PASS VERIFICATION
          - NLI filter: High-recall contradiction detection (RoBERTa-large-MNLI)
          - First pass: VIOLATES vs DOES_NOT_VIOLATE (Qwen)
          - Second pass: TRUE_VIOLATION vs COMPATIBLE (Qwen)
          - Only "VIOLATES" + "TRUE_VIOLATION" = violation
    3. Decision: ANY violation â†’ 0, NO violations â†’ 1
    
    CONSTRAINT CATEGORIZATION (Section 3.3):
    - 5 types: belief, prohibition, motivation, background_fact, fear
    - Each constraint now has explicit type metadata
    - BACKGROUND_FACT constraints skipped (no violation search needed)
    
    NLI FILTER (CRITICAL FOR 85-95% ACCURACY):
    - RoBERTa-large-MNLI provides high-recall contradiction signal
    - Filters chunks before expensive Qwen calls
    - Prevents similarity â‰  contradiction problem
    
    TWO-PASS VERIFICATION:
    - Pass 1: Initial VIOLATES judgment
    - Pass 2: Confirm TRUE_VIOLATION (logically impossible)
    - Reduces false positives from vague wording
    
    STRICT RULES:
    - NO end-to-end generation
    - NO chain-of-thought
    - NO agent frameworks
    - Binary decisions only
    - One violation = contradiction
    
    Args:
        vector_store: PathwayVectorStore with ingested novel
        model: Qwen LLM
        tokenizer: Qwen tokenizer
        reranker: bge-reranker-large CrossEncoder
        statement: Backstory statement to verify
        novel_id: Novel identifier for logging
        nli_model: RoBERTa-large-MNLI for contradiction detection (optional but recommended)
        nli_tokenizer: Tokenizer for NLI model
        enable_refinement: Whether to use self-refinement loop (default: True)
        max_refinement_attempts: Max query refinement iterations (default: 2)
        logger: Optional logger from evaluation.py
        
    Returns:
        Dict with {
            'prediction': int (0=inconsistent, 1=consistent),
            'constraints': List[Dict],  # Now includes type info
            'violations': List[Dict],
            'summary': str
        }
    """
    print("\n" + "="*80)
    print(f"CONSTRAINT CONSISTENCY CHECK: {novel_id}")
    print("="*80)
    print(f"Statement: {statement}")
    print(f"NLI filter: {'ENABLED' if nli_model is not None else 'DISABLED'}")
    print(f"Self-refinement: {'ENABLED' if enable_refinement else 'DISABLED'}")
    if enable_refinement:
        print(f"Max refinement attempts: {max_refinement_attempts}")
    print("="*80)
    
    # Step 1: Extract constraints WITH TYPES (Section 3.3)
    from evaluation import parse_constraints_with_types
    
    prompt = prompts.CONSTRAINT_EXTRACTION_PROMPT.format(statement=statement)
    raw_output = generate_with_qwen(model, tokenizer, prompt, max_new_tokens=1024)
    
    constraints = parse_constraints_with_types(raw_output, logger)
    
    if not constraints:
        print("\nâš  No constraints extracted â†’ Assume consistent")
        print(f"Debug - Raw output: {raw_output[:200]}...")
        return {
            'prediction': 1,
            'constraints': [],
            'violations': [],
            'summary': "No constraints to check"
        }
    
    # Step 1.5: PRIORITIZE and CAP constraints (CRITICAL FOR ACCURACY)
    constraints = prioritize_constraints(constraints)
    original_count = len(constraints)
    constraints = constraints[:config.MAX_CONSTRAINTS_PER_STATEMENT]
    
    if original_count > config.MAX_CONSTRAINTS_PER_STATEMENT:
        print(f"\nâš  Capped constraints from {original_count} to {config.MAX_CONSTRAINTS_PER_STATEMENT}")
    
    print(f"\nExtracted {len(constraints)} constraint(s) with types:")
    for i, c in enumerate(constraints, 1):
        print(f"  {i}. [{c['type'].upper()}] {c['constraint'][:80]}...")
    
    # Step 2: Check each constraint (WITH SOFT SCORING if enabled)
    all_violations = []
    violation_scores = []  # For soft aggregation mode
    
    for i, constraint_obj in enumerate(constraints, 1):
        constraint_text = constraint_obj['constraint']
        constraint_type = constraint_obj['type']
        
        print(f"\n{'='*80}")
        print(f"CONSTRAINT {i}/{len(constraints)} [{constraint_type.upper()}]")
        print(f"{'='*80}")
        
        # CRITICAL: Skip non-violatable constraint types
        if constraint_type.upper() not in config.VIOLATABLE_TYPES:
            print(f"\nâš  {constraint_type.upper()} constraint â†’ Skip violation search")
            print(f"Reason: Only {config.VIOLATABLE_TYPES} types can be violated")
            continue
        
        # Step 2a: Find establishment position
        establishment = find_constraint_establishment(
            vector_store,
            model,
            tokenizer,
            constraint_text,
            reranker
        )
        
        if not establishment['found']:
            print(f"\nâš  Constraint not established in novel â†’ Skip")
            continue
        
        established_at = establishment['position']
        
        # Step 2b: Generate violation query
        violation_query = generate_violation_query(model, tokenizer, constraint_text)
        
        # Step 2c: Search for violations WITH NLI FILTER + TWO-PASS VERIFICATION
        # Use new NLI-based search if NLI model available, otherwise fallback to legacy
        if nli_model is not None and nli_tokenizer is not None:
            print(f"\nðŸ”¬ Using NLI-filtered two-pass verification")
            violation_found, evidence = search_for_violations_with_nli(
                vector_store,
                model,
                tokenizer,
                nli_model,
                nli_tokenizer,
                constraint_text,
                violation_query,
                established_at,
                reranker
            )
        else:
            print(f"\nâš  WARNING: NLI model not available, using legacy search")
            print(f"   Accuracy will be lower without NLI filter!")
            # Fallback to old method (with refinement if enabled)
            if enable_refinement:
                violation_found, evidence = search_for_violations_with_refinement(
                    vector_store,
                    model,
                    tokenizer,
                    constraint_text,
                    violation_query,
                    established_at,
                    reranker,
                    max_refinement_attempts=max_refinement_attempts,
                    logger=logger
                )
            else:
                violation_found, evidence = search_for_violations(
                    vector_store,
                    model,
                    tokenizer,
                    constraint_text,
                    violation_query,
                    established_at,
                    reranker
                )
        
        if violation_found:
            # Add constraint type to evidence
            evidence['constraint_type'] = constraint_type
            all_violations.append(evidence)
            
            print(f"\n{'='*80}")
            print("âœ— POTENTIAL VIOLATION DETECTED")
            print(f"{'='*80}")
            print(f"Constraint type: {constraint_type}")
            print(f"Constraint: {constraint_text}")
            print(f"Established at: position {established_at}")
            print(f"Violated at: position {evidence['violation_position']}")
            print("="*80)
            
            # BINARY MODE: Return immediately (one violation = 0)
            if config.USE_BINARY_MODE:
                print(f"\n[BINARY MODE] One violation â†’ inconsistent")
                return {
                    'prediction': 0,
                    'constraints': constraints,
                    'violations': all_violations,
                    'summary': f"Violation found for {constraint_type}: {constraint_text[:80]}..."
                }
            else:
                # SOFT SCORING MODE: Calculate violation score
                # Score based on: NLI confidence + rerank score + LLM confidence
                nli_score = evidence.get('nli_score', 0.8)  # Default high if not provided
                rerank_score = evidence.get('rerank_score', 0.7)
                llm_confidence = 1.0  # TRUE_VIOLATION confirmed
                
                violation_score = (
                    config.SCORE_WEIGHT_NLI * nli_score +
                    config.SCORE_WEIGHT_RERANK * rerank_score +
                    config.SCORE_WEIGHT_LLM * llm_confidence
                )
                
                violation_scores.append(violation_score)
                print(f"Violation score: {violation_score:.3f} (NLI:{nli_score:.2f}, Rerank:{rerank_score:.2f}, LLM:{llm_confidence:.2f})")
    
    # Step 3: Final decision (SOFT SCORING MODE)
    if config.USE_SOFT_SCORING and violation_scores:
        max_violation_score = max(violation_scores)
        avg_violation_score = sum(violation_scores) / len(violation_scores)
        
        print(f"\n{'='*80}")
        print("SOFT SCORING DECISION")
        print(f"{'='*80}")
        print(f"Violations found: {len(violation_scores)}")
        print(f"Max violation score: {max_violation_score:.3f}")
        print(f"Avg violation score: {avg_violation_score:.3f}")
        print(f"Decision threshold: {config.VIOLATION_DECISION_THRESHOLD}")
        
        if max_violation_score >= config.VIOLATION_DECISION_THRESHOLD:
            prediction = 0
            summary = f"Inconsistent (max score: {max_violation_score:.3f} >= {config.VIOLATION_DECISION_THRESHOLD})"
            print(f"âœ— DECISION: INCONSISTENT")
        else:
            prediction = 1
            summary = f"Consistent (max score: {max_violation_score:.3f} < {config.VIOLATION_DECISION_THRESHOLD})"
            print(f"âœ“ DECISION: CONSISTENT (violations below threshold)")
        
        print("="*80)
        
        return {
            'prediction': prediction,
            'constraints': constraints,
            'violations': all_violations,
            'summary': summary,
            'max_violation_score': max_violation_score,
            'avg_violation_score': avg_violation_score
        }
    
    # Step 3 (Binary mode fallback): No violations found
    print(f"\n{'='*80}")
    print("âœ“ ALL CONSTRAINTS CONSISTENT")
    print(f"{'='*80}")
    print(f"Checked {len(constraints)} constraint(s)")
    print("No violations detected")
    print("="*80)
    
    return {
        'prediction': 1,
        'constraints': constraints,
        'violations': [],
        'summary': "All constraints consistent"
    }


