{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e202446",
   "metadata": {},
   "source": [
    "# Constraint Consistency Checker - Google Colab Setup\n",
    "\n",
    "Competition-grade system using Qwen2.5-14B (4-bit), bge-m3, bge-reranker, and Pathway.\n",
    "\n",
    "**Setup:** Runtime → Change runtime type → GPU (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01972f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad805dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Drive or clone repo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/IIT_KDSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch transformers sentence-transformers bitsandbytes accelerate rank-bm25 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d92eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify setup\n",
    "import torch\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test\n",
    "!python quickstart.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342766f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models (first time: ~10GB download)\n",
    "from models import load_llm, load_embedder, load_reranker\n",
    "\n",
    "model, tokenizer = load_llm()\n",
    "embedder = load_embedder()\n",
    "reranker = load_reranker()\n",
    "\n",
    "print(f\"\\nGPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc82c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single example\n",
    "from pipeline import ingest_novel, process_statement\n",
    "\n",
    "sample_novel = \"\"\"Chapter 1: Dr. John Smith worked at the hospital for 20 years.\n",
    "Chapter 2: John treated patients daily.\n",
    "Chapter 3: Lawyer John Smith argued his case in court.\"\"\"\n",
    "\n",
    "vector_store = ingest_novel(sample_novel, \"test\", embedder)\n",
    "\n",
    "models = {'qwen': model, 'tokenizer': tokenizer, 'embedder': embedder, 'reranker': reranker}\n",
    "result, evidence = process_statement(vector_store, models, \"John Smith is a doctor.\")\n",
    "\n",
    "print(f\"\\nResult: {result} (0=violation, 1=consistent)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ef3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full pipeline\n",
    "!python run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "import pandas as pd\n",
    "results = pd.read_csv(\"outputs/results.csv\")\n",
    "print(f\"Total: {len(results)}\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17678534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "if 'label' in results.columns:\n",
    "    acc = (results['prediction'] == results['label']).mean()\n",
    "    print(f\"Accuracy: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results\n",
    "from google.colab import files\n",
    "files.download('outputs/results.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
